{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbzQQYtbrY7V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import os\n",
        "\n",
        "fileList = os.listdir('/content/drive/MyDrive/prova/dades')\n",
        "csv_files = [file for file in fileList if file[-3:] == \"csv\"]\n",
        "batch_size = 1000\n",
        "\n",
        "# Cargar y procesar los datos\n",
        "def load_and_process_data(csv_file):\n",
        "    data = pd.read_csv(csv_file)\n",
        "    data.dropna(subset=['num_docks_available', 'Llocs'], inplace=True)\n",
        "    data = data[data[\"num_docks_available\"] >= 0]\n",
        "    data = data[data[\"Llocs\"] >= 0]\n",
        "    data = data[data[\"num_docks_available\"] <= 60]\n",
        "    data = data[data[\"Llocs\"] <= 60]\n",
        "    data = data[data[\"num_docks_available\"] <= data[\"Llocs\"]]\n",
        "    X = data[['station_id', 'hour', 'dayofweek','month', 'Rain_Lectura']]\n",
        "    Y = (data['num_docks_available'] / data['Llocs']).fillna(0)\n",
        "    return X, Y\n",
        "\n",
        "# Cargar y procesar los datos para predicciones\n",
        "def load_and_process_data2(csv_file):\n",
        "    data = pd.read_csv(csv_file)\n",
        "    X = data[['station_id', 'hour', 'dayofweek', 'month', 'Rain_Lectura']]\n",
        "    return X\n",
        "\n",
        "# Crear listas para almacenar los lotes de entrenamiento y prueba\n",
        "X_train_batches = []\n",
        "Y_train_batches = []\n",
        "\n",
        "# Iterar sobre los archivos CSV y dividir en lotes de entrenamiento y prueba\n",
        "for csv_file in csv_files[:]:\n",
        "    print(csv_file)\n",
        "    # Cargar y procesar los datos en el lote\n",
        "    X, Y = load_and_process_data('/content/drive/MyDrive/prova/dades/' + csv_file)\n",
        "\n",
        "    # Agregar los lotes a las listas\n",
        "    X_train_batches.append(X)\n",
        "    Y_train_batches.append(Y)\n",
        "\n",
        "# Combinar todos los lotes de entrenamiento\n",
        "X_train = pd.concat(X_train_batches)\n",
        "Y_train = pd.concat(Y_train_batches)\n",
        "\n",
        "# Escalar los valores numéricos en el rango [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Crear un modelo de árbol de decisión\n",
        "model = DecisionTreeRegressor()\n",
        "\n",
        "# Entrenar el modelo en los conjuntos de entrenamiento\n",
        "model.fit(X_train_scaled, Y_train)\n",
        "\n",
        "# Realizar predicciones con el modelo entrenado\n",
        "new_data = load_and_process_data2('/content/drive/MyDrive/prova/test/submission.csv')\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "predictions = model.predict(new_data_scaled)\n",
        "\n",
        "# Obtener los IDs de la columna correspondiente en new_data_scaled\n",
        "ids = new_data.index.values\n",
        "\n",
        "# Crear un DataFrame con las predicciones y los IDs\n",
        "df = pd.DataFrame({'index': ids, 'percentage_docks_available': predictions})\n",
        "\n",
        "# Definir la ruta y el nombre del archivo CSV\n",
        "csv_file = 'predicciones2.csv'\n",
        "\n",
        "# Guardar el DataFrame en el archivo CSV\n",
        "df.to_csv(csv_file, index=False)\n"
      ]
    }
  ]
}