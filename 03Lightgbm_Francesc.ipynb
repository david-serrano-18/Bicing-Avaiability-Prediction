{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6LP8z7ux/2K3N3qGz0Zjg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXrz8jNLkzbs","executionInfo":{"status":"ok","timestamp":1688033182011,"user_tz":-120,"elapsed":21763,"user":{"displayName":"Francesc Polls Agell","userId":"08524325674868416435"}},"outputId":"dce14f37-27d5-40d0-dd1b-cfc74f34d5af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","import os\n","from google.colab import files\n","import pandas as pd\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error"],"metadata":{"id":"BXoOruYrk0ae","executionInfo":{"status":"ok","timestamp":1688033478218,"user_tz":-120,"elapsed":5,"user":{"displayName":"Francesc Polls Agell","userId":"08524325674868416435"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["fileList = os.listdir('/content/drive/MyDrive/prova/dades')\n","csv_files = [file for file in fileList if file[-3:] == \"csv\"]\n","batch_size = 1000\n","csv_files=sorted(csv_files)\n","\n","# Crear una lista vacÃ­a para almacenar los DataFrames de cada archivo\n","dataframes = []\n","\n","# Leer cada archivo CSV y agregarlo a la lista de DataFrames\n","for archivo in csv_files:\n","\n","    df = pd.read_csv('/content/drive/MyDrive/prova/dades/'+archivo)\n","    df=df.loc[:, ['num_docks_available', 'Llocs','station_id','hour','dayofweek','month','Wind','Rain']]\n","    dataframes.append(df)\n","\n","# Combinar todos los DataFrames en uno solo\n","dataframe_final = pd.concat(dataframes, ignore_index=True)\n","\n","# Mostrar el DataFrame resultante\n","print(dataframe_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbTGNlkdoqoA","executionInfo":{"status":"ok","timestamp":1688033560880,"user_tz":-120,"elapsed":75283,"user":{"displayName":"Francesc Polls Agell","userId":"08524325674868416435"}},"outputId":"339870b7-81e6-4043-c8be-fdce74f252c3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["         num_docks_available  Llocs  station_id  hour  dayofweek  month  Wind  \\\n","0                   5.500000   46.0           1   0.0          4    1.0     0   \n","1                   5.000000   46.0           1   1.0          4    1.0     0   \n","2                   5.000000   46.0           1   2.0          4    1.0     0   \n","3                   5.000000   46.0           1   3.0          4    1.0     0   \n","4                   5.000000   46.0           1   4.0          4    1.0     0   \n","...                      ...    ...         ...   ...        ...    ...   ...   \n","8819374            21.250000   22.0         519  18.0          4    9.0     0   \n","8819375            18.666667   22.0         519  19.0          4    9.0     0   \n","8819376            16.916667   22.0         519  20.0          4    9.0     0   \n","8819377            17.666667   22.0         519  21.0          4    9.0     0   \n","8819378            18.333333   22.0         519  22.0          4    9.0     0   \n","\n","         Rain  \n","0           1  \n","1           1  \n","2           1  \n","3           1  \n","4           1  \n","...       ...  \n","8819374     0  \n","8819375     0  \n","8819376     0  \n","8819377     0  \n","8819378     0  \n","\n","[8819379 rows x 8 columns]\n"]}]},{"cell_type":"code","source":["\n","\n","# Cargar los datos en lotes y realizar transformaciones\n","def load_and_process_data(data):\n","\n","    data.dropna(subset=['num_docks_available', 'Llocs', 'station_id', 'hour', 'dayofweek', 'month', 'Wind', 'Rain'], inplace=True)\n","    data['porcio'] = data['num_docks_available'] / data['Llocs']\n","    data['festa'] = (data['dayofweek'] > 5) & (data['month'] == 8)\n","    data['winter'] = (data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)\n","    data['spring'] = (data['month'] >= 3) & (data['month'] <= 5)\n","    data['summer'] = (data['month'] >= 6) & (data['month'] <= 8)\n","    data['fall'] = (data['month'] >= 9) & (data['month'] <= 11)\n","\n","    # X = data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain']]\n","    X= data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain','Wind']]\n","\n","    Y = data['porcio']\n","\n","    return X, Y\n","def load_and_process_data2(csv_file):\n","    data = pd.read_csv(csv_file)\n","\n","    data['festa'] = (data['dayofweek'] > 5) & (data['month'] == 8)\n","    data['winter'] = (data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)\n","    data['spring'] = (data['month'] >= 3) & (data['month'] <= 5)\n","    data['summer'] = (data['month'] >= 6) & (data['month'] <= 8)\n","    data['fall'] = (data['month'] >= 9) & (data['month'] <= 11)\n","\n","    X = data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain']]\n","    X= data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain','Wind']]\n","\n","\n","    return X\n","\n","# Cargar y procesar los datos de entrenamiento\n","X_train, Y_train = load_and_process_data(dataframe_final)\n","\n","categorical_features = ['station_id']\n","lgb_train = lgb.Dataset(X_train, label=Y_train, categorical_feature=categorical_features)\n","model = lgb.train({}, lgb_train)\n","\n","\n","# Realizar predicciones con el modelo entrenado\n","new_data = load_and_process_data2('/content/drive/MyDrive/prova/test/submission.csv')\n","# new_data_scaled = scaler.transform(new_data)\n","new_data_scaled = new_data\n","\n","predictions = model.predict(new_data_scaled)\n","# Obtener los IDs de la columna correspondiente en new_data_scaled\n","ids = new_data.index.values\n","\n","# Crear un DataFrame con las predicciones y los IDs\n","df = pd.DataFrame({'index': ids, 'percentage_docks_available': predictions})\n","\n","# Definir la ruta y el nombre del archivo CSV\n","csv_file = 'lightgbm.csv'\n","\n","# Guardar el DataFrame en el archivo CSV\n","df.to_csv(csv_file, index=False)\n","files.download('/content/'+csv_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"bBvzFXKek8l-","executionInfo":{"status":"ok","timestamp":1688035229997,"user_tz":-120,"elapsed":65520,"user":{"displayName":"Francesc Polls Agell","userId":"08524325674868416435"}},"outputId":"b1d0fa0a-2993-4163-c2f7-8ce997179eb3"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n","  _log_warning('Using categorical_feature in Dataset.')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.694175 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 548\n","[LightGBM] [Info] Number of data points in the train set: 8819379, number of used features: 9\n","[LightGBM] [Info] Start training from score 0.625679\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a6cd7d34-2efe-428f-a000-762174916008\", \"lightgbm.csv\", 1365315)"]},"metadata":{}}]},{"cell_type":"code","source":["\n","\n","# Cargar los datos en lotes y realizar transformaciones\n","def load_and_process_data(data):\n","\n","    data.dropna(subset=['num_docks_available', 'Llocs', 'station_id', 'hour', 'dayofweek', 'month', 'Wind', 'Rain'], inplace=True)\n","    data['porcio'] = data['num_docks_available'] / data['Llocs']\n","    data['festa'] = (data['dayofweek'] > 5) & (data['month'] == 8)\n","    data['winter'] = (data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)\n","    data['spring'] = (data['month'] >= 3) & (data['month'] <= 5)\n","    data['summer'] = (data['month'] >= 6) & (data['month'] <= 8)\n","    data['fall'] = (data['month'] >= 9) & (data['month'] <= 11)\n","\n","    # X = data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain']]\n","    X= data[['station_id', 'hour', 'festa', 'month','dayofweek', 'Rain','Wind']]\n","    Y = data['porcio']\n","\n","    return X, Y\n","def load_and_process_data2(csv_file):\n","    data = pd.read_csv(csv_file)\n","\n","    data['festa'] = (data['dayofweek'] > 5) & (data['month'] == 8)\n","    data['winter'] = (data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)\n","    data['spring'] = (data['month'] >= 3) & (data['month'] <= 5)\n","    data['summer'] = (data['month'] >= 6) & (data['month'] <= 8)\n","    data['fall'] = (data['month'] >= 9) & (data['month'] <= 11)\n","\n","    # X = data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain']]\n","    X= data[['station_id', 'hour', 'festa', 'month','dayofweek', 'Rain','Wind']]\n","\n","\n","    return X\n","\n","# Cargar y procesar los datos de entrenamiento\n","X_train, Y_train = load_and_process_data(dataframe_final)\n","\n","categorical_features = ['station_id', 'month','dayofweek']\n","lgb_train = lgb.Dataset(X_train, label=Y_train, categorical_feature=categorical_features)\n","model = lgb.train({}, lgb_train)\n","\n","\n","# Realizar predicciones con el modelo entrenado\n","new_data = load_and_process_data2('/content/drive/MyDrive/prova/test/submission.csv')\n","# new_data_scaled = scaler.transform(new_data)\n","new_data_scaled = new_data\n","\n","predictions = model.predict(new_data_scaled)\n","# Obtener los IDs de la columna correspondiente en new_data_scaled\n","ids = new_data.index.values\n","\n","# Crear un DataFrame con las predicciones y los IDs\n","df = pd.DataFrame({'index': ids, 'percentage_docks_available': predictions})\n","\n","# Definir la ruta y el nombre del archivo CSV\n","csv_file = 'lightgbm.csv'\n","\n","# Guardar el DataFrame en el archivo CSV\n","df.to_csv(csv_file, index=False)\n","files.download('/content/'+csv_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"xOls_DGYojqi","executionInfo":{"status":"ok","timestamp":1688034852660,"user_tz":-120,"elapsed":67896,"user":{"displayName":"Francesc Polls Agell","userId":"08524325674868416435"}},"outputId":"93cdf39b-8e52-4747-8ee5-d3bef77e7daf"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n","  _log_warning('Using categorical_feature in Dataset.')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.334697 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 553\n","[LightGBM] [Info] Number of data points in the train set: 8819379, number of used features: 6\n","[LightGBM] [Info] Start training from score 0.625679\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_dc46d05d-30dc-4449-9d26-295f36744e8c\", \"lightgbm.csv\", 1365057)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"nAnxnuUBuVY1"},"execution_count":null,"outputs":[]}]}