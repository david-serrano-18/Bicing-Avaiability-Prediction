{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21763,
     "status": "ok",
     "timestamp": 1688033182011,
     "user": {
      "displayName": "Francesc Polls Agell",
      "userId": "08524325674868416435"
     },
     "user_tz": -120
    },
    "id": "KXrz8jNLkzbs",
    "outputId": "dce14f37-27d5-40d0-dd1b-cfc74f34d5af"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688033478218,
     "user": {
      "displayName": "Francesc Polls Agell",
      "userId": "08524325674868416435"
     },
     "user_tz": -120
    },
    "id": "BXoOruYrk0ae"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75283,
     "status": "ok",
     "timestamp": 1688033560880,
     "user": {
      "displayName": "Francesc Polls Agell",
      "userId": "08524325674868416435"
     },
     "user_tz": -120
    },
    "id": "rbTGNlkdoqoA",
    "outputId": "339870b7-81e6-4043-c8be-fdce74f252c3"
   },
   "outputs": [],
   "source": [
    "fileList = os.listdir('/content/drive/MyDrive/prova/dades')\n",
    "csv_files = [file for file in fileList if file[-3:] == \"csv\"]\n",
    "batch_size = 1000\n",
    "csv_files=sorted(csv_files)\n",
    "\n",
    "# Crear una lista vacÃ­a para almacenar los DataFrames de cada archivo\n",
    "dataframes = []\n",
    "\n",
    "# Leer cada archivo CSV y agregarlo a la lista de DataFrames\n",
    "for archivo in csv_files:\n",
    "\n",
    "    df = pd.read_csv('/content/drive/MyDrive/prova/dades/'+archivo)\n",
    "    df=df.loc[:, ['num_docks_available', 'Llocs','station_id','hour','dayofweek','month','Wind','Rain']]\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combinar todos los DataFrames en uno solo\n",
    "dataframe_final = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(dataframe_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "executionInfo": {
     "elapsed": 65520,
     "status": "ok",
     "timestamp": 1688035229997,
     "user": {
      "displayName": "Francesc Polls Agell",
      "userId": "08524325674868416435"
     },
     "user_tz": -120
    },
    "id": "bBvzFXKek8l-",
    "outputId": "b1d0fa0a-2993-4163-c2f7-8ce997179eb3"
   },
   "outputs": [],
   "source": [
    "# Cargar los datos en lotes y realizar transformaciones\n",
    "def load_and_process_data(data):\n",
    "\n",
    "    data.dropna(subset=['num_docks_available', 'Llocs', 'station_id', 'hour', 'dayofweek', 'month', 'Wind', 'Rain'], inplace=True)\n",
    "    data['porcio'] = data['num_docks_available'] / data['Llocs']\n",
    "    data['festa'] = (data['dayofweek'] > 5) & (data['month'] == 8)\n",
    "    data['winter'] = (data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)\n",
    "    data['spring'] = (data['month'] >= 3) & (data['month'] <= 5)\n",
    "    data['summer'] = (data['month'] >= 6) & (data['month'] <= 8)\n",
    "    data['fall'] = (data['month'] >= 9) & (data['month'] <= 11)\n",
    "\n",
    "    # X = data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain']]\n",
    "    X= data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain','Wind']]\n",
    "\n",
    "    Y = data['porcio']\n",
    "\n",
    "    return X, Y\n",
    "def load_and_process_data2(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    data['festa'] = (data['dayofweek'] > 5) & (data['month'] == 8)\n",
    "    data['winter'] = (data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)\n",
    "    data['spring'] = (data['month'] >= 3) & (data['month'] <= 5)\n",
    "    data['summer'] = (data['month'] >= 6) & (data['month'] <= 8)\n",
    "    data['fall'] = (data['month'] >= 9) & (data['month'] <= 11)\n",
    "\n",
    "    X = data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain']]\n",
    "    X= data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain','Wind']]\n",
    "\n",
    "\n",
    "    return X\n",
    "\n",
    "# Cargar y procesar los datos de entrenamiento\n",
    "X_train, Y_train = load_and_process_data(dataframe_final)\n",
    "\n",
    "categorical_features = ['station_id']\n",
    "lgb_train = lgb.Dataset(X_train, label=Y_train, categorical_feature=categorical_features)\n",
    "model = lgb.train({}, lgb_train)\n",
    "\n",
    "# Realizar predicciones con el modelo entrenado\n",
    "new_data = load_and_process_data2('/content/drive/MyDrive/prova/test/submission.csv')\n",
    "# new_data_scaled = scaler.transform(new_data)\n",
    "new_data_scaled = new_data\n",
    "\n",
    "predictions = model.predict(new_data_scaled)\n",
    "# Obtener los IDs de la columna correspondiente en new_data_scaled\n",
    "ids = new_data.index.values\n",
    "\n",
    "# Crear un DataFrame con las predicciones y los IDs\n",
    "df = pd.DataFrame({'index': ids, 'percentage_docks_available': predictions})\n",
    "\n",
    "# Definir la ruta y el nombre del archivo CSV\n",
    "csv_file = 'lightgbm.csv'\n",
    "\n",
    "# Guardar el DataFrame en el archivo CSV\n",
    "df.to_csv(csv_file, index=False)\n",
    "files.download('/content/'+csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "executionInfo": {
     "elapsed": 67896,
     "status": "ok",
     "timestamp": 1688034852660,
     "user": {
      "displayName": "Francesc Polls Agell",
      "userId": "08524325674868416435"
     },
     "user_tz": -120
    },
    "id": "xOls_DGYojqi",
    "outputId": "93cdf39b-8e52-4747-8ee5-d3bef77e7daf"
   },
   "outputs": [],
   "source": [
    "# Cargar los datos en lotes y realizar transformaciones\n",
    "def load_and_process_data(data):\n",
    "\n",
    "    data.dropna(subset=['num_docks_available', 'Llocs', 'station_id', 'hour', 'dayofweek', 'month', 'Wind', 'Rain'], inplace=True)\n",
    "    data['porcio'] = data['num_docks_available'] / data['Llocs']\n",
    "    data['festa'] = (data['dayofweek'] > 5) & (data['month'] == 8)\n",
    "    data['winter'] = (data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)\n",
    "    data['spring'] = (data['month'] >= 3) & (data['month'] <= 5)\n",
    "    data['summer'] = (data['month'] >= 6) & (data['month'] <= 8)\n",
    "    data['fall'] = (data['month'] >= 9) & (data['month'] <= 11)\n",
    "\n",
    "    # X = data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain']]\n",
    "    X= data[['station_id', 'hour', 'festa', 'month','dayofweek', 'Rain','Wind']]\n",
    "    Y = data['porcio']\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def load_and_process_data2(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    data['festa'] = (data['dayofweek'] > 5) & (data['month'] == 8)\n",
    "    data['winter'] = (data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)\n",
    "    data['spring'] = (data['month'] >= 3) & (data['month'] <= 5)\n",
    "    data['summer'] = (data['month'] >= 6) & (data['month'] <= 8)\n",
    "    data['fall'] = (data['month'] >= 9) & (data['month'] <= 11)\n",
    "\n",
    "    # X = data[['station_id', 'hour', 'festa', 'winter', 'spring', 'summer', 'fall', 'Rain']]\n",
    "    X= data[['station_id', 'hour', 'festa', 'month','dayofweek', 'Rain','Wind']]\n",
    "\n",
    "\n",
    "    return X\n",
    "\n",
    "# Cargar y procesar los datos de entrenamiento\n",
    "X_train, Y_train = load_and_process_data(dataframe_final)\n",
    "\n",
    "categorical_features = ['station_id', 'month','dayofweek']\n",
    "lgb_train = lgb.Dataset(X_train, label=Y_train, categorical_feature=categorical_features)\n",
    "model = lgb.train({}, lgb_train)\n",
    "\n",
    "# Realizar predicciones con el modelo entrenado\n",
    "new_data = load_and_process_data2('/content/drive/MyDrive/prova/test/submission.csv')\n",
    "# new_data_scaled = scaler.transform(new_data)\n",
    "new_data_scaled = new_data\n",
    "\n",
    "predictions = model.predict(new_data_scaled)\n",
    "# Obtener los IDs de la columna correspondiente en new_data_scaled\n",
    "ids = new_data.index.values\n",
    "\n",
    "# Crear un DataFrame con las predicciones y los IDs\n",
    "df = pd.DataFrame({'index': ids, 'percentage_docks_available': predictions})\n",
    "\n",
    "# Definir la ruta y el nombre del archivo CSV\n",
    "csv_file = 'lightgbm.csv'\n",
    "\n",
    "# Guardar el DataFrame en el archivo CSV\n",
    "df.to_csv(csv_file, index=False)\n",
    "files.download('/content/'+csv_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6LP8z7ux/2K3N3qGz0Zjg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
